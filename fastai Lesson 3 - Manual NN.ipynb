{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e8053f",
   "metadata": {},
   "source": [
    "First, I'll reproduce the code from Jeremy Howard's notebook:\n",
    "https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c1ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "from fastai.basics import *\n",
    "\n",
    "plt.rc('figure', dpi=90)\n",
    "\n",
    "def plot_function(f, title=None, min=-2.1, max=2.1, color='r', ylim=None):\n",
    "    x = torch.linspace(min,max, 100)[:,None]\n",
    "    if ylim: plt.ylim(ylim)\n",
    "    plt.plot(x, f(x), color)\n",
    "    if title is not None: plt.title(title)\n",
    "\n",
    "\n",
    "def f(x): return 3*x**2 + 2*x + 1\n",
    "def quad(a, b, c, x): return a * x ** 2 + b * x + c\n",
    "def make_quad(a, b, c): return partial(quad, a, b, c)\n",
    "def mean_absolute_error(predictions, actuals): return torch.abs(predictions - actuals).mean()\n",
    "def noise(x, scale): return numpy.random.normal(scale=scale, size=x.shape)\n",
    "def add_noise(x, mult, add): return x * (1 + noise(x, mult)) + noise(x, add)\n",
    "numpy.random.seed(42)\n",
    "x = torch.linspace(-2, 2, steps=20)[:,None]\n",
    "y = add_noise(f(x), 0.15, 1.5)\n",
    "def quad_mean_absolute_error(params):\n",
    "\tf = make_quad(*params)\n",
    "\treturn mean_absolute_error(f(x), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64de10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2.4219, dtype=torch.float64, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = torch.tensor([1.1, 1.1, 1.1])\n",
    "abc.requires_grad_()\n",
    "\n",
    "loss = quad_mean_absolute_error(abc)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8b3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f966f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-1.3529, -0.0316, -0.5000])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f031789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=2.40\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    abc -= abc.grad*0.01\n",
    "    loss = quad_mean_absolute_error(abc)\n",
    "    \n",
    "print(f'loss={loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06e58d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=0; loss=2.40\n",
      "Step=1; loss=2.36\n",
      "Step=2; loss=2.30\n",
      "Step=3; loss=2.21\n",
      "Step=4; loss=2.11\n",
      "Step=5; loss=1.98\n",
      "Step=6; loss=1.85\n",
      "Step=7; loss=1.72\n",
      "Step=8; loss=1.58\n",
      "Step=9; loss=1.46\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    loss = quad_mean_absolute_error(abc)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): abc -= abc.grad*0.01\n",
    "    print(f'Step={i}; loss={loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a6fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectified_linear(m,b,x):\n",
    "    y = m*x+b\n",
    "    return torch.clip(y, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702cc098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(FloatSlider(value=1.5, description='m', max=4.5, min=-1.5), FloatSlider(value=1.5, descrâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4b17cb44f064865bb3c451d7d155a51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(m=1.5,b=1.5)\n",
    "def plot_relu(m,b):\n",
    "    plot_function(partial(rectified_linear, m,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe47436",
   "metadata": {},
   "source": [
    "### Now let's try and \"manually\" (meaning: without a predefined nn architecture) create a super-basic NN and optimize it for the Titanic Competition\n",
    "https://www.kaggle.com/competitions/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b71abff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  pClass1  \\\n0           0       3    male  22.0      1      0   7.2500        S        0   \n1           1       1  female  38.0      1      0  71.2833        C        1   \n2           1       3  female  26.0      0      0   7.9250        S        0   \n3           1       1  female  35.0      1      0  53.1000        S        1   \n4           0       3    male  35.0      0      0   8.0500        S        0   \n..        ...     ...     ...   ...    ...    ...      ...      ...      ...   \n885         0       3  female  39.0      0      5  29.1250        Q        0   \n886         0       2    male  27.0      0      0  13.0000        S        0   \n887         1       1  female  19.0      0      0  30.0000        S        1   \n889         1       1    male  26.0      0      0  30.0000        C        1   \n890         0       3    male  32.0      0      0   7.7500        Q        0   \n\n     pClass2  isMale  isEmbarkedS  isEmbarkedC  ageNormalized  fareNormalized  \n0          0       1            1            0         0.2750        0.860338  \n1          0       0            0            1         0.4750        1.852988  \n2          0       0            1            0         0.3250        0.898999  \n3          0       0            1            0         0.4375        1.725095  \n4          0       1            1            0         0.4375        0.905796  \n..       ...     ...          ...          ...            ...             ...  \n885        0       0            0            0         0.4875        1.464266  \n886        1       1            1            0         0.3375        1.113943  \n887        0       0            1            0         0.2375        1.477121  \n889        0       1            0            1         0.3250        1.477121  \n890        0       1            0            0         0.4000        0.889302  \n\n[712 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>pClass1</th>\n      <th>pClass2</th>\n      <th>isMale</th>\n      <th>isEmbarkedS</th>\n      <th>isEmbarkedC</th>\n      <th>ageNormalized</th>\n      <th>fareNormalized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.2750</td>\n      <td>0.860338</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.4750</td>\n      <td>1.852988</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.3250</td>\n      <td>0.898999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.4375</td>\n      <td>1.725095</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.4375</td>\n      <td>0.905796</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>29.1250</td>\n      <td>Q</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.4875</td>\n      <td>1.464266</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>2</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>S</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.3375</td>\n      <td>1.113943</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>S</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.2375</td>\n      <td>1.477121</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>C</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.3250</td>\n      <td>1.477121</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>Q</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.4000</td>\n      <td>0.889302</td>\n    </tr>\n  </tbody>\n</table>\n<p>712 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import csv\n",
    "csv = pd.read_csv(\"data/titanic/train.csv\")\n",
    "\n",
    "# cleanup superfluous data and convert columns to usable numbers\n",
    "dataframe = pd.DataFrame(csv)\n",
    "dataframe = dataframe.drop(columns=[\"PassengerId\",\"Ticket\", \"Name\",\"Cabin\"])\n",
    "# drop rows with empty cells\n",
    "dataframe = dataframe.dropna()\n",
    "\n",
    "dataframe['pClass1'] = dataframe['Pclass'].apply(lambda pclass : 1 if pclass == 1 else 0 )\n",
    "dataframe['pClass2'] = dataframe['Pclass'].apply(lambda pclass : 1 if pclass == 2 else 0)\n",
    "dataframe['isMale'] = dataframe['Sex'].apply(lambda gender : 1 if gender == 'male' else 0)\n",
    "dataframe['isEmbarkedS'] = dataframe['Embarked'].apply(lambda harbour: 1 if harbour == 'S' else 0)\n",
    "dataframe['isEmbarkedC'] = dataframe['Embarked'].apply(lambda harbour: 1 if harbour == 'C' else 0)\n",
    "dataframe['ageNormalized'] = dataframe['Age'].apply(lambda age: age / dataframe['Age'].max())\n",
    "dataframe['fareNormalized'] = dataframe['Fare'].apply(lambda fare: numpy.log10(fare))\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a31e6",
   "metadata": {},
   "source": [
    "#### Initialize our 2 layer NN with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a09051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9696, 0.7751, 0.9395, 0.8948, 0.5979, 0.9219, 0.0885, 0.1960, 0.0452,\n         0.3253],\n        [0.3887, 0.2713, 0.8287, 0.3568, 0.2809, 0.5427, 0.1409, 0.8022, 0.0746,\n         0.9869]], dtype=torch.float64, requires_grad=True)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor(pd.DataFrame(np.random.random((2,10))).values)\n",
    "params.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1a800",
   "metadata": {},
   "source": [
    "#### Some preparations: Create a cleaned up dataframe with only the data we need and layers for receiving our calculations\n",
    "#### Apply reLU to cleaned df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "405c5221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [14], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# calculate loss based on predictions - actual survival rate\u001B[39;00m\n\u001B[1;32m     13\u001B[0m loss \u001B[38;5;241m=\u001B[39m mae(torch\u001B[38;5;241m.\u001B[39mtensor(predictions\u001B[38;5;241m.\u001B[39mvalues), torch\u001B[38;5;241m.\u001B[39mtensor(dataframe[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSurvived\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues))\n\u001B[0;32m---> 14\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# todo: \u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# - tensors, gradient - how to multiply in a way that results in usable tensors?\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# - gradient function\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# - optimization loop\u001B[39;00m\n",
      "File \u001B[0;32m~/dev/projects/personal/ai/deeplearning-exercises/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/projects/personal/ai/deeplearning-exercises/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "cleanDf = dataframe[['SibSp','Parch','pClass1','pClass2','isMale','isEmbarkedS','isEmbarkedC','ageNormalized','fareNormalized']]\n",
    "layer1,layer2,predictions = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "def mae(preds, acts): return (torch.abs(preds-acts)).mean()\n",
    "\n",
    "# make two layers of reLUs and sum them up to get our predictions\n",
    "for i in range(0,9):\n",
    "  layer1[i] = cleanDf.iloc[:,i:i+1].apply(lambda x : params[0,i].item() * x + params[0,9].item()).clip(lower=0)\n",
    "  layer2[i] = cleanDf.iloc[:,i:i+1].apply(lambda x : params[1,i].item() * x + params[1,9].item()).clip(lower=0)\n",
    "    \n",
    "predictions = layer1.add(layer2).sum(axis=1)\n",
    "# calculate loss based on predictions - actual survival rate\n",
    "loss = mae(torch.tensor(predictions.values), torch.tensor(dataframe['Survived'].values))\n",
    "loss.backward()\n",
    "\n",
    "# todo: \n",
    "# - tensors, gradient - how to multiply in a way that results in usable tensors?\n",
    "# - gradient function\n",
    "# - optimization loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
